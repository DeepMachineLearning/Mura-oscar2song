{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oscar\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 321,230\n",
      "Trainable params: 321,228\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/50\n",
      " - 3s - loss: 1.2098 - acc: 0.5515 - val_loss: 0.7080 - val_acc: 0.7167\n",
      "Epoch 2/50\n",
      " - 2s - loss: 0.7386 - acc: 0.7333 - val_loss: 0.5791 - val_acc: 0.7733\n",
      "Epoch 3/50\n",
      " - 2s - loss: 0.6203 - acc: 0.7787 - val_loss: 0.4968 - val_acc: 0.8200\n",
      "Epoch 4/50\n",
      " - 2s - loss: 0.5698 - acc: 0.7833 - val_loss: 0.4793 - val_acc: 0.8300\n",
      "Epoch 5/50\n",
      " - 2s - loss: 0.5120 - acc: 0.8120 - val_loss: 0.4568 - val_acc: 0.8233\n",
      "Epoch 6/50\n",
      " - 2s - loss: 0.4764 - acc: 0.8319 - val_loss: 0.4181 - val_acc: 0.8567\n",
      "Epoch 7/50\n",
      " - 2s - loss: 0.4535 - acc: 0.8419 - val_loss: 0.4135 - val_acc: 0.8583\n",
      "Epoch 8/50\n",
      " - 2s - loss: 0.4344 - acc: 0.8513 - val_loss: 0.3982 - val_acc: 0.8633\n",
      "Epoch 9/50\n",
      " - 2s - loss: 0.4075 - acc: 0.8563 - val_loss: 0.3988 - val_acc: 0.8650\n",
      "Epoch 10/50\n",
      " - 2s - loss: 0.4051 - acc: 0.8591 - val_loss: 0.4304 - val_acc: 0.8383\n",
      "Epoch 11/50\n",
      " - 2s - loss: 0.3884 - acc: 0.8544 - val_loss: 0.4000 - val_acc: 0.8483\n",
      "Epoch 12/50\n",
      " - 2s - loss: 0.3869 - acc: 0.8587 - val_loss: 0.4020 - val_acc: 0.8533\n",
      "Epoch 13/50\n",
      " - 2s - loss: 0.3664 - acc: 0.8648 - val_loss: 0.3784 - val_acc: 0.8717\n",
      "Epoch 14/50\n",
      " - 2s - loss: 0.3498 - acc: 0.8730 - val_loss: 0.3820 - val_acc: 0.8733\n",
      "Epoch 15/50\n",
      " - 2s - loss: 0.3425 - acc: 0.8769 - val_loss: 0.4109 - val_acc: 0.8767\n",
      "Epoch 16/50\n",
      " - 2s - loss: 0.3360 - acc: 0.8774 - val_loss: 0.3738 - val_acc: 0.8650\n",
      "Epoch 17/50\n",
      " - 2s - loss: 0.3189 - acc: 0.8878 - val_loss: 0.3638 - val_acc: 0.8850\n",
      "Epoch 18/50\n",
      " - 2s - loss: 0.3286 - acc: 0.8807 - val_loss: 0.3553 - val_acc: 0.8950\n",
      "Epoch 19/50\n",
      " - 2s - loss: 0.3175 - acc: 0.8859 - val_loss: 0.3602 - val_acc: 0.8883\n",
      "Epoch 20/50\n",
      " - 2s - loss: 0.3042 - acc: 0.8852 - val_loss: 0.3588 - val_acc: 0.8717\n",
      "Epoch 21/50\n",
      " - 2s - loss: 0.3029 - acc: 0.8898 - val_loss: 0.3524 - val_acc: 0.8767\n",
      "Epoch 22/50\n",
      " - 2s - loss: 0.2984 - acc: 0.8863 - val_loss: 0.4123 - val_acc: 0.8800\n",
      "Epoch 23/50\n",
      " - 2s - loss: 0.2982 - acc: 0.8896 - val_loss: 0.3640 - val_acc: 0.8767\n",
      "Epoch 24/50\n",
      " - 2s - loss: 0.2983 - acc: 0.8911 - val_loss: 0.3828 - val_acc: 0.8750\n",
      "Epoch 25/50\n",
      " - 2s - loss: 0.2822 - acc: 0.8976 - val_loss: 0.3704 - val_acc: 0.8800\n",
      "Epoch 26/50\n",
      " - 2s - loss: 0.2706 - acc: 0.8987 - val_loss: 0.4261 - val_acc: 0.8717\n",
      "Epoch 27/50\n",
      " - 2s - loss: 0.2722 - acc: 0.8985 - val_loss: 0.4011 - val_acc: 0.8933\n",
      "Epoch 28/50\n",
      " - 2s - loss: 0.2745 - acc: 0.8972 - val_loss: 0.3833 - val_acc: 0.8767\n",
      "Epoch 29/50\n",
      " - 2s - loss: 0.2600 - acc: 0.9052 - val_loss: 0.4115 - val_acc: 0.8733\n",
      "Epoch 30/50\n",
      " - 2s - loss: 0.2533 - acc: 0.9048 - val_loss: 0.4130 - val_acc: 0.8733\n",
      "Epoch 31/50\n",
      " - 2s - loss: 0.2504 - acc: 0.9078 - val_loss: 0.4538 - val_acc: 0.8767\n",
      "Epoch 32/50\n",
      " - 2s - loss: 0.2611 - acc: 0.9065 - val_loss: 0.3996 - val_acc: 0.8850\n",
      "Epoch 33/50\n",
      " - 2s - loss: 0.2638 - acc: 0.9030 - val_loss: 0.4269 - val_acc: 0.8767\n",
      "Epoch 34/50\n",
      " - 2s - loss: 0.2455 - acc: 0.9130 - val_loss: 0.4681 - val_acc: 0.8717\n",
      "Epoch 35/50\n",
      " - 2s - loss: 0.2417 - acc: 0.9081 - val_loss: 0.4598 - val_acc: 0.8833\n",
      "Epoch 36/50\n",
      " - 2s - loss: 0.2440 - acc: 0.9139 - val_loss: 0.4863 - val_acc: 0.8683\n",
      "Epoch 37/50\n",
      " - 2s - loss: 0.2174 - acc: 0.9204 - val_loss: 0.4289 - val_acc: 0.8850\n",
      "Epoch 38/50\n",
      " - 2s - loss: 0.2331 - acc: 0.9104 - val_loss: 0.4345 - val_acc: 0.8833\n",
      "Epoch 39/50\n",
      " - 2s - loss: 0.2214 - acc: 0.9193 - val_loss: 0.4543 - val_acc: 0.8883\n",
      "Epoch 40/50\n",
      " - 2s - loss: 0.2333 - acc: 0.9143 - val_loss: 0.4360 - val_acc: 0.8817\n",
      "Epoch 41/50\n",
      " - 2s - loss: 0.2410 - acc: 0.9150 - val_loss: 0.4308 - val_acc: 0.8783\n",
      "Epoch 42/50\n",
      " - 2s - loss: 0.2308 - acc: 0.9154 - val_loss: 0.4580 - val_acc: 0.8850\n",
      "Epoch 43/50\n",
      " - 2s - loss: 0.2279 - acc: 0.9174 - val_loss: 0.4541 - val_acc: 0.8783\n",
      "Epoch 44/50\n",
      " - 2s - loss: 0.2138 - acc: 0.9224 - val_loss: 0.4576 - val_acc: 0.8783\n",
      "Epoch 45/50\n",
      " - 2s - loss: 0.2151 - acc: 0.9185 - val_loss: 0.4869 - val_acc: 0.8767\n",
      "Epoch 46/50\n",
      " - 2s - loss: 0.2108 - acc: 0.9219 - val_loss: 0.4615 - val_acc: 0.8817\n",
      "Epoch 47/50\n",
      " - 2s - loss: 0.2083 - acc: 0.9207 - val_loss: 0.4560 - val_acc: 0.8750\n",
      "Epoch 48/50\n",
      " - 2s - loss: 0.2074 - acc: 0.9211 - val_loss: 0.4729 - val_acc: 0.8817\n",
      "Epoch 49/50\n",
      " - 2s - loss: 0.2082 - acc: 0.9270 - val_loss: 0.4204 - val_acc: 0.8833\n",
      "Epoch 50/50\n",
      " - 2s - loss: 0.1997 - acc: 0.9291 - val_loss: 0.4399 - val_acc: 0.8783\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_3 to have shape (10,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7fbe4ec9db63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'test_loss:%2.2f,test_accuracy:%2.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;31m#Loss Curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_3 to have shape (10,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# Import all required modules\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from keras import backend as K\n",
    "#from keras import optimizers\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D,MaxPooling2D,Dropout,Flatten,BatchNormalization,Activation,InputLayer\n",
    "from keras.utils import np_utils\n",
    "#from keras.callbacks import EarlyStopping\n",
    "# keras settings\n",
    "#{\n",
    "#    \"image_data_format\": \"channels_last\",\n",
    "#    \"epsilon\": 1e-07,\n",
    "#    \"backend\": \"tensorflow\",\n",
    "#    \"floatx\": \"float32\"\n",
    "#}\n",
    "# Early stopping is not used\n",
    "#EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None)\n",
    "\n",
    "# Parameters\n",
    "kernel_size=3\n",
    "conv_kernels_1=32\n",
    "conv_kernels_2=64\n",
    "drop_prop_1=0.25\n",
    "drop_prop_2=0.5\n",
    "\n",
    "pool_size=2\n",
    "dense_size=512\n",
    "\n",
    "batch_size=32\n",
    "epochs=50\n",
    "\n",
    "# Prepare data\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Use less data to save computing time for prototype\n",
    "data_percent=10\n",
    "X_train = X_train[:X_train.shape[0]//data_percent]\n",
    "y_train = y_train[:y_train.shape[0]//data_percent]\n",
    "X_test = X_test[:X_test.shape[0]//data_percent]\n",
    "y_test = y_test[:y_test.shape[0]//data_percent]\n",
    "\n",
    "n_train, height, width = X_train.shape\n",
    "depth = 1 # grayscale images\n",
    "n_test = X_test.shape[0]\n",
    "n_classes = np.unique(y_train).shape[0]\n",
    "input_shape=(height,width,depth)\n",
    "\n",
    "# Normalize data to [0, 1] range\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= np.max(X_train)\n",
    "X_test /= np.max(X_test)\n",
    "X_train = X_train.reshape(n_train,height,width,depth)\n",
    "X_test = X_test.reshape(n_test,height,width,depth)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "def create_cnn_model(): \n",
    "\tcnn = Sequential()\n",
    "\t\n",
    "\t# Add input layer\n",
    "\tcnn.add(InputLayer(input_shape=input_shape))\n",
    "\t\n",
    "\t# Normalization\n",
    "\tcnn.add(BatchNormalization())\n",
    "\t\n",
    "\t# Conv + Maxpooling\n",
    "\tcnn.add(Conv2D(conv_kernels_1, (kernel_size, kernel_size), padding=\"same\",activation=\"relu\"))\n",
    "\tcnn.add(MaxPooling2D((pool_size,pool_size)))\n",
    "\t# Dropout\n",
    "\tcnn.add(Dropout(drop_prop_1))\n",
    "\t\n",
    "\tcnn.add(Conv2D(conv_kernels_2, (kernel_size, kernel_size)))\n",
    "\tcnn.add(MaxPooling2D((pool_size,pool_size)))\n",
    "\t\n",
    "\t# Dropout\n",
    "\tcnn.add(Dropout(drop_prop_2))\n",
    "\t\n",
    "\tcnn.add(Conv2D(conv_kernels_2, (kernel_size, kernel_size)))\n",
    "\tcnn.add(MaxPooling2D((pool_size,pool_size)))\n",
    "\t\n",
    "\t# Cannot add more layers as the size is less than kernel_size\n",
    "\t#cnn.add(Conv2D(conv_kernels_2, (kernel_size, kernel_size)))\n",
    "\t#cnn.add(MaxPooling2D((pool_size,pool_size)))\n",
    "\t\n",
    "\tcnn.add(Flatten())\n",
    "\tcnn.add(Dense(dense_size, activation='relu'))\n",
    "\tcnn.add(Dropout(drop_prop_2))\n",
    "\tcnn.add(Dense(dense_size//2, activation='relu'))\n",
    "\tcnn.add(Dropout(drop_prop_2))\n",
    "\tcnn.add(Dense(n_classes, activation='softmax'))\n",
    "\tcnn.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=\"Adam\")\n",
    "\treturn cnn\n",
    "\n",
    "# Create a model\n",
    "model=create_cnn_model()\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.10, batch_size=batch_size, epochs=epochs, verbose=2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print ('test_loss:%2.2f,test_accuracy:%2.2f' % (test_loss,test_accuracy))\n",
    "#Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves',fontsize=16)\n",
    " \n",
    "# Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
